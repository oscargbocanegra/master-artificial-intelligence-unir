{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c98372b",
   "metadata": {},
   "source": [
    "# Modulo - NPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3387cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulo de Procesamiento de NLP separado en pasos\n",
    "%pip install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22f5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Carga y preprocesamiento de texto\n",
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Limpieza y normalización del texto.\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        return ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dec92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Extracción de términos clave\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "class KeyTermExtractor:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def extract_key_terms(self, documents, max_features=100):\n",
    "        \"\"\"Extraer términos clave usando TF-IDF.\"\"\"\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(documents)\n",
    "        terms = self.vectorizer.get_feature_names_out()\n",
    "        scores = np.asarray(tfidf_matrix.sum(axis=0)).flatten()\n",
    "        term_scores = list(zip(terms, scores))\n",
    "        return sorted(term_scores, key=lambda x: x[1], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590b376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Análisis de co-ocurrencias\n",
    "class CooccurrenceAnalyzer:\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def analyze_cooccurrences(self, documents, threshold=0.1):\n",
    "        \"\"\"Analizar co-ocurrencias de términos clave.\"\"\"\n",
    "        doc_terms = [set(self.preprocessor.preprocess_text(doc).split()) for doc in documents]\n",
    "        cooccurrence_matrix = {}\n",
    "\n",
    "        for i, terms1 in enumerate(doc_terms):\n",
    "            for j, terms2 in enumerate(doc_terms):\n",
    "                if i != j:\n",
    "                    common_terms = terms1.intersection(terms2)\n",
    "                    for term in common_terms:\n",
    "                        cooccurrence_matrix[term] = cooccurrence_matrix.get(term, 0) + 1\n",
    "\n",
    "        return {k: v for k, v in cooccurrence_matrix.items() if v > threshold}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603928ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Actualización de la ontología\n",
    "class OntologyUpdater:\n",
    "    def update_ontology(self, extracted_terms, ontology_terms):\n",
    "        \"\"\"Actualizar la ontología con nuevos términos.\"\"\"\n",
    "        new_terms = set(term for term, score in extracted_terms) - set(ontology_terms)\n",
    "        updated_ontology = list(set(ontology_terms).union(new_terms))\n",
    "        return updated_ontology, new_terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049e04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Cálculo de métricas\n",
    "class OntologyMetrics:\n",
    "    def calculate_semantic_precision(self, ontology_terms, extracted_terms):\n",
    "        \"\"\"Calcular la precisión semántica.\"\"\"\n",
    "        extracted_set = set(term for term, score in extracted_terms)\n",
    "        correct_terms = extracted_set.intersection(set(ontology_terms))\n",
    "        precision = len(correct_terms) / len(extracted_set) if extracted_set else 0\n",
    "        return precision\n",
    "\n",
    "    def calculate_coverage(self, ontology_terms, extracted_terms):\n",
    "        \"\"\"Calcular la cobertura ontológica.\"\"\"\n",
    "        extracted_set = set(term for term, score in extracted_terms)\n",
    "        coverage = len(extracted_set.intersection(set(ontology_terms))) / len(ontology_terms) if ontology_terms else 0\n",
    "        return coverage\n",
    "\n",
    "    def calculate_consistency(self, ontology_terms):\n",
    "        \"\"\"Calcular la consistencia ontológica.\"\"\"\n",
    "        return 1.0  # Placeholder, dependería de reglas de consistencia específicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9558ba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Términos clave: [('loan', 1.0157281407543406), ('rate', 0.6949357650865606), ('apply', 0.5046113401371842), ('car', 0.5046113401371842), ('customer', 0.5046113401371842), ('home', 0.40914567838389126), ('low', 0.40914567838389126), ('personal', 0.40914567838389126), ('typically', 0.40914567838389126), ('education', 0.3968745408286403), ('enrollment', 0.3968745408286403), ('institution', 0.3968745408286403), ('recognize', 0.3968745408286403), ('require', 0.3968745408286403), ('verification', 0.3968745408286403)]\n",
      "Co-ocurrencias: {'rate': 2, 'interest': 2, 'loan': 6}\n",
      "Ontología actualizada: ['rate', 'personal', 'customer', 'education', 'institution', 'home', 'enrollment', 'typically', 'recognize', 'low', 'verification', 'apply', 'require', 'interest rate', 'loan', 'car']\n",
      "Nuevos términos agregados: {'typically', 'recognize', 'rate', 'personal', 'customer', 'low', 'institution', 'verification', 'apply', 'require', 'enrollment'}\n",
      "\n",
      "Términos clave en tabla:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan</td>\n",
       "      <td>1.015728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rate</td>\n",
       "      <td>0.694936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apply</td>\n",
       "      <td>0.504611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car</td>\n",
       "      <td>0.504611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customer</td>\n",
       "      <td>0.504611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>low</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>personal</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>typically</td>\n",
       "      <td>0.409146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>education</td>\n",
       "      <td>0.396875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>enrollment</td>\n",
       "      <td>0.396875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>institution</td>\n",
       "      <td>0.396875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>recognize</td>\n",
       "      <td>0.396875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>require</td>\n",
       "      <td>0.396875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>verification</td>\n",
       "      <td>0.396875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term     Score\n",
       "0           loan  1.015728\n",
       "1           rate  0.694936\n",
       "2          apply  0.504611\n",
       "3            car  0.504611\n",
       "4       customer  0.504611\n",
       "5           home  0.409146\n",
       "6            low  0.409146\n",
       "7       personal  0.409146\n",
       "8      typically  0.409146\n",
       "9      education  0.396875\n",
       "10    enrollment  0.396875\n",
       "11   institution  0.396875\n",
       "12     recognize  0.396875\n",
       "13       require  0.396875\n",
       "14  verification  0.396875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Co-ocurrencias en tabla:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Cooccurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rate</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interest</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loan</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  Cooccurrence\n",
       "0      rate             2\n",
       "1  interest             2\n",
       "2      loan             6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ontología actualizada en tabla:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>institution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>enrollment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>typically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recognize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>verification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>require</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>interest rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term\n",
       "0            rate\n",
       "1        personal\n",
       "2        customer\n",
       "3       education\n",
       "4     institution\n",
       "5            home\n",
       "6      enrollment\n",
       "7       typically\n",
       "8       recognize\n",
       "9             low\n",
       "10   verification\n",
       "11          apply\n",
       "12        require\n",
       "13  interest rate\n",
       "14           loan\n",
       "15            car"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    # Descargar el modelo de spaCy\n",
    "    #!python -m spacy download en_core_web_sm\n",
    "\n",
    "    # Datos de prueba\n",
    "    sample_texts = [\n",
    "        \"The customer applied for a car loan with an interest rate of 5.2%.\",\n",
    "        \"Home loans typically have lower interest rates than personal loans.\",\n",
    "        \"Education loans require verification of enrollment in a recognized institution.\",\n",
    "    ]\n",
    "\n",
    "    # Ontología inicial\n",
    "    initial_ontology = [\"car\", \"loan\", \"interest rate\", \"home\", \"education\"]\n",
    "\n",
    "    # Instanciar los componentes\n",
    "    preprocessor = TextPreprocessor()\n",
    "    extractor = KeyTermExtractor()\n",
    "    analyzer = CooccurrenceAnalyzer(preprocessor)\n",
    "    updater = OntologyUpdater()\n",
    "\n",
    "    # Preprocesar textos\n",
    "    preprocessed_texts = [preprocessor.preprocess_text(text) for text in sample_texts]\n",
    "\n",
    "    # Extraer términos clave\n",
    "    key_terms = extractor.extract_key_terms(preprocessed_texts)\n",
    "    print(\"Términos clave:\", key_terms)\n",
    "\n",
    "    # Analizar co-ocurrencias\n",
    "    cooccurrences = analyzer.analyze_cooccurrences(sample_texts)\n",
    "    print(\"Co-ocurrencias:\", cooccurrences)\n",
    "\n",
    "    # Actualizar ontología\n",
    "    updated_ontology, new_terms = updater.update_ontology(key_terms, initial_ontology)\n",
    "    print(\"Ontología actualizada:\", updated_ontology)\n",
    "    print(\"Nuevos términos agregados:\", new_terms)\n",
    "\n",
    "    # Crear DataFrame para mostrar los resultados\n",
    "    key_terms_df = pd.DataFrame(key_terms, columns=['Term', 'Score'])\n",
    "    cooccurrences_df = pd.DataFrame(list(cooccurrences.items()), columns=['Term', 'Cooccurrence'])\n",
    "\n",
    "    # Mostrar los resultados en tablas\n",
    "    print(\"\\nTérminos clave en tabla:\")\n",
    "    display(key_terms_df)\n",
    "\n",
    "    print(\"\\nCo-ocurrencias en tabla:\")\n",
    "    display(cooccurrences_df)\n",
    "\n",
    "    print(\"\\nOntología actualizada en tabla:\")\n",
    "    updated_ontology_df = pd.DataFrame(updated_ontology, columns=['Term'])\n",
    "    display(updated_ontology_df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5d5fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('business', 1.0), ('car', 1.0), ('education', 1.0), ('home', 1.0)],\n",
       " {},\n",
       " ['business', 'home', 'credit', 'loan', 'education', 'interest', 'car'],\n",
       " {'business'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer textos del dataset para probar el módulo de NLP\n",
    "file_path = \"D:/datasets/loan_dataset.csv\"\n",
    "loan_data = pd.read_csv(file_path)\n",
    "\n",
    "sample_texts_from_data = loan_data['loan_purpose'].unique()  # Tomar los propósitos de préstamo como ejemplos de texto\n",
    "\n",
    "# Ontología inicial simulada\n",
    "initial_ontology = ['loan', 'interest', 'credit', 'car', 'education', 'home']\n",
    "\n",
    "# Instanciar los componentes del módulo de NLP\n",
    "preprocessor = TextPreprocessor()\n",
    "extractor = KeyTermExtractor()\n",
    "analyzer = CooccurrenceAnalyzer(preprocessor)\n",
    "updater = OntologyUpdater()\n",
    "\n",
    "# Preprocesar los textos\n",
    "preprocessed_texts = [preprocessor.preprocess_text(text) for text in sample_texts_from_data]\n",
    "\n",
    "# Extraer términos clave\n",
    "key_terms = extractor.extract_key_terms(preprocessed_texts)\n",
    "\n",
    "# Analizar co-ocurrencias\n",
    "cooccurrences = analyzer.analyze_cooccurrences(sample_texts_from_data)\n",
    "\n",
    "# Actualizar la ontología\n",
    "updated_ontology, new_terms = updater.update_ontology(key_terms, initial_ontology)\n",
    "\n",
    "key_terms, cooccurrences, updated_ontology, new_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb51f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinir las clases del módulo para ajustarlas al análisis actual\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Limpieza y normalización del texto.\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        return ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "class KeyTermExtractor:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def extract_key_terms(self, documents, max_features=100):\n",
    "        \"\"\"Extraer términos clave usando TF-IDF.\"\"\"\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(documents)\n",
    "        terms = self.vectorizer.get_feature_names_out()\n",
    "        scores = np.asarray(tfidf_matrix.sum(axis=0)).flatten()\n",
    "        term_scores = list(zip(terms, scores))\n",
    "        return sorted(term_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "class CooccurrenceAnalyzer:\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def analyze_cooccurrences(self, documents, threshold=0.1):\n",
    "        \"\"\"Analizar co-ocurrencias de términos clave.\"\"\"\n",
    "        doc_terms = [set(self.preprocessor.preprocess_text(doc).split()) for doc in documents]\n",
    "        cooccurrence_matrix = {}\n",
    "\n",
    "        for i, terms1 in enumerate(doc_terms):\n",
    "            for j, terms2 in enumerate(doc_terms):\n",
    "                if i != j:\n",
    "                    common_terms = terms1.intersection(terms2)\n",
    "                    for term in common_terms:\n",
    "                        cooccurrence_matrix[term] = cooccurrence_matrix.get(term, 0) + 1\n",
    "\n",
    "        return {k: v for k, v in cooccurrence_matrix.items() if v > threshold}\n",
    "\n",
    "class OntologyUpdater:\n",
    "    def update_ontology(self, extracted_terms, ontology_terms):\n",
    "        \"\"\"Actualizar la ontología con nuevos términos.\"\"\"\n",
    "        new_terms = set(term for term, score in extracted_terms) - set(ontology_terms)\n",
    "        updated_ontology = list(set(ontology_terms).union(new_terms))\n",
    "        return updated_ontology, new_terms\n",
    "\n",
    "class OntologyMetrics:\n",
    "    def calculate_semantic_precision(self, ontology_terms, extracted_terms):\n",
    "        \"\"\"Calcular la precisión semántica.\"\"\"\n",
    "        extracted_set = set(term for term, score in extracted_terms)\n",
    "        correct_terms = extracted_set.intersection(set(ontology_terms))\n",
    "        precision = len(correct_terms) / len(extracted_set) if extracted_set else 0\n",
    "        return precision\n",
    "\n",
    "    def calculate_coverage(self, ontology_terms, extracted_terms):\n",
    "        \"\"\"Calcular la cobertura ontológica.\"\"\"\n",
    "        extracted_set = set(term for term, score in extracted_terms)\n",
    "        coverage = len(extracted_set.intersection(set(ontology_terms))) / len(ontology_terms) if ontology_terms else 0\n",
    "        return coverage\n",
    "\n",
    "    def calculate_consistency(self, ontology_terms):\n",
    "        \"\"\"Calcular la consistencia ontológica.\"\"\"\n",
    "        return 1.0  # Placeholder para reglas específicas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fffb6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('business', 1.0), ('car', 1.0), ('education', 1.0), ('home', 1.0)],\n",
       " {},\n",
       " ['business', 'home', 'credit', 'loan', 'education', 'interest', 'car'],\n",
       " {'business'},\n",
       " 0.75,\n",
       " 0.5,\n",
       " 1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probar el módulo con el dataset cargado\n",
    "preprocessor = TextPreprocessor()\n",
    "extractor = KeyTermExtractor()\n",
    "analyzer = CooccurrenceAnalyzer(preprocessor)\n",
    "updater = OntologyUpdater()\n",
    "metrics = OntologyMetrics()\n",
    "\n",
    "# Preprocesar textos del dataset\n",
    "preprocessed_texts = [preprocessor.preprocess_text(text) for text in sample_texts_from_data]\n",
    "\n",
    "# Extraer términos clave\n",
    "key_terms = extractor.extract_key_terms(preprocessed_texts)\n",
    "\n",
    "# Analizar co-ocurrencias\n",
    "cooccurrences = analyzer.analyze_cooccurrences(sample_texts_from_data)\n",
    "\n",
    "# Actualizar ontología\n",
    "updated_ontology, new_terms = updater.update_ontology(key_terms, initial_ontology)\n",
    "\n",
    "# Calcular métricas\n",
    "precision = metrics.calculate_semantic_precision(initial_ontology, key_terms)\n",
    "coverage = metrics.calculate_coverage(initial_ontology, key_terms)\n",
    "consistency = metrics.calculate_consistency(initial_ontology)\n",
    "\n",
    "# Mostrar resultados\n",
    "key_terms[:10], cooccurrences, updated_ontology, new_terms, precision, coverage, consistency\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iartificial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
